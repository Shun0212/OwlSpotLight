import os
import json
from pathlib import Path
from threading import Lock
import faiss
import numpy as np
from typing import List, Dict, Any, Optional

class ClusterIndex:
    def __init__(self, name: str, path: Path):
        self.name = name
        self.path = path
        self.path.mkdir(parents=True, exist_ok=True)
        self.meta_path = path / "meta.json"
        self.index_path = path / "faiss.index"
        self.file_map_path = path / "file_map.json"
        self.last_update_path = path / "last_update.json"
        self.lock = Lock()
        self.meta = self._load_json(self.meta_path, default=[])  # List[dict]
        self.file_map = self._load_json(self.file_map_path, default={})  # file -> [func_id]
        self.last_update = self._load_json(self.last_update_path, default={})  # file -> mtime
        self.index = self._load_faiss_index()

    def _load_json(self, path: Path, default):
        if path.exists():
            try:
                with open(path, "r", encoding="utf-8") as f:
                    return json.load(f)
            except Exception as e:
                print(f"Error loading {path}: {e}")
                return default
        return default

    def _save_json(self, path: Path, obj):
        self.path.mkdir(parents=True, exist_ok=True)
        with open(path, "w", encoding="utf-8") as f:
            json.dump(obj, f, ensure_ascii=False, indent=2)

    def _load_faiss_index(self):
        if self.index_path.exists():
            try:
                return faiss.read_index(str(self.index_path))
            except Exception as e:
                print(f"Error loading FAISS index {self.index_path}: {e}")
                return None
        return None

    def save(self):
        with self.lock:
            self.path.mkdir(parents=True, exist_ok=True)
            self._save_json(self.meta_path, self.meta)
            self._save_json(self.file_map_path, self.file_map)
            self._save_json(self.last_update_path, self.last_update)
            if self.index is not None:
                try:
                    faiss.write_index(self.index, str(self.index_path))
                except Exception as e:
                    print(f"Error saving FAISS index {self.index_path}: {e}")

    def search(self, q_emb: np.ndarray, k: int):
        with self.lock:
            if self.index is None or len(self.meta) == 0:
                return []
            try:
                D, I = self.index.search(q_emb, min(k, len(self.meta)))
                results = []
                for i in I[0]:
                    if i != -1 and i < len(self.meta):
                        results.append(self.meta[i])
                return results
            except Exception as e:
                print(f"Error during search in cluster {self.name}: {e}")
                return []

    def is_up_to_date(self, files: List[str]) -> bool:
        """æŒ‡å®šã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆã«å¯¾ã—ã¦ã‚¯ãƒ©ã‚¹ã‚¿ãŒæœ€æ–°ã‹ãƒã‚§ãƒƒã‚¯"""
        with self.lock:
            for file_path in files:
                if not os.path.exists(file_path):
                    continue
                current_mtime = os.path.getmtime(file_path)
                if file_path not in self.last_update:
                    return False
                if abs(current_mtime - self.last_update[file_path]) > 1e-3:
                    return False
            return True

    def get_changed_files(self, files: List[str]) -> tuple[List[str], List[str]]:
        """è¿½åŠ ãƒ»å¤‰æ›´ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã¨å‰Šé™¤ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—"""
        with self.lock:
            added_or_modified = []
            for file_path in files:
                if not os.path.exists(file_path):
                    continue
                current_mtime = os.path.getmtime(file_path)
                if (file_path not in self.last_update or 
                    abs(current_mtime - self.last_update[file_path]) > 1e-3):
                    added_or_modified.append(file_path)
            
            deleted = [f for f in self.last_update.keys() if f not in files or not os.path.exists(f)]
            return added_or_modified, deleted

    def update_files(self, added_funcs: List[Dict[str, Any]], deleted_files: List[str], 
                    embeddings: Optional[np.ndarray] = None):
        """ãƒ•ã‚¡ã‚¤ãƒ«ã®è¿½åŠ ãƒ»å‰Šé™¤ã«åŸºã¥ã„ã¦ã‚¯ãƒ©ã‚¹ã‚¿ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’æ›´æ–°"""
        with self.lock:
            # å‰Šé™¤å‡¦ç†
            if deleted_files:
                remove_indices = set()
                for file in deleted_files:
                    if file in self.file_map:
                        for func_idx in self.file_map[file]:
                            remove_indices.add(func_idx)
                        del self.file_map[file]
                    if file in self.last_update:
                        del self.last_update[file]
                
                if remove_indices:
                    # å‰Šé™¤å¯¾è±¡ä»¥å¤–ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ä¿æŒ
                    new_meta = []
                    old_to_new_idx = {}
                    new_idx = 0
                    for old_idx, func in enumerate(self.meta):
                        if old_idx not in remove_indices:
                            old_to_new_idx[old_idx] = new_idx
                            new_meta.append(func)
                            new_idx += 1
                    
                    self.meta = new_meta
                    
                    # ãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒƒãƒ—ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’æ›´æ–°
                    new_file_map = {}
                    for file, indices in self.file_map.items():
                        new_indices = []
                        for old_idx in indices:
                            if old_idx in old_to_new_idx:
                                new_indices.append(old_to_new_idx[old_idx])
                        if new_indices:
                            new_file_map[file] = new_indices
                    self.file_map = new_file_map
                    
                    # FAISSã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å†æ§‹ç¯‰ï¼ˆå‰Šé™¤ã•ã‚ŒãŸè¦ç´ ã‚’é™¤ãï¼‰
                    if self.index is not None and len(self.meta) > 0:
                        # æ®‹ã£ãŸãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã«å¯¾å¿œã™ã‚‹åŸ‹ã‚è¾¼ã¿ã‚’æŠ½å‡ºã—ã¦å†æ§‹ç¯‰
                        # æ³¨æ„: ã“ã®å®Ÿè£…ã§ã¯åŸ‹ã‚è¾¼ã¿ã®å†è¨ˆç®—ãŒå¿…è¦
                        self.index = None  # å†æ§‹ç¯‰ãŒå¿…è¦
            
            # è¿½åŠ å‡¦ç†
            if added_funcs and embeddings is not None:
                start_idx = len(self.meta)
                self.meta.extend(added_funcs)
                
                # ãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒƒãƒ—ã‚’æ›´æ–°
                for i, func in enumerate(added_funcs):
                    file_path = func.get('file')
                    if file_path:
                        if file_path not in self.file_map:
                            self.file_map[file_path] = []
                        self.file_map[file_path].append(start_idx + i)
                        # mtimeã‚’æ›´æ–°
                        if os.path.exists(file_path):
                            self.last_update[file_path] = os.path.getmtime(file_path)
                
                # FAISSã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’æ›´æ–°
                if self.index is None:
                    if len(embeddings) > 0:
                        self.index = faiss.IndexFlatL2(embeddings.shape[1])
                        self.index.add(embeddings)
                else:
                    self.index.add(embeddings)
            
            self.save()

    def rebuild_from_functions(self, funcs: List[Dict[str, Any]], embeddings: Optional[np.ndarray] = None):
        """é–¢æ•°ãƒªã‚¹ãƒˆã‹ã‚‰å®Œå…¨ã«ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å†æ§‹ç¯‰"""
        from tqdm import tqdm
        
        with self.lock:
            self.meta = funcs
            self.file_map = {}
            self.last_update = {}
            
            # ãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒƒãƒ—ã¨mtimeã‚’æ§‹ç¯‰
            print(f"ğŸ”„ Building file map for {len(funcs)} functions in cluster '{self.name}'...")
            for i, func in enumerate(tqdm(funcs, desc=f"Mapping functions ({self.name})", disable=len(funcs) < 10)):
                file_path = func.get('file')
                if file_path:
                    if file_path not in self.file_map:
                        self.file_map[file_path] = []
                    self.file_map[file_path].append(i)
                    if os.path.exists(file_path):
                        self.last_update[file_path] = os.path.getmtime(file_path)
            
            # FAISSã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å†æ§‹ç¯‰
            if embeddings is not None and len(embeddings) > 0:
                print(f"ğŸ”„ Building FAISS index for cluster '{self.name}' with {len(embeddings)} embeddings...")
                self.index = faiss.IndexFlatL2(embeddings.shape[1])
                self.index.add(embeddings)
            else:
                self.index = None
            
            self.save()
        # è¿½åŠ /æ›´æ–°: add_with_ids, å‰Šé™¤: remove_ids
        # meta, file_map, indexã‚’æ›´æ–°
